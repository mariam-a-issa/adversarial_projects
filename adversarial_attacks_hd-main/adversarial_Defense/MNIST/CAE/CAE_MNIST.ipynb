{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d33e7d3e-8998-44a0-9a75-bcce7e51cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import onlinehd\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from onlinehd import CAE\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "# import pdb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a891d7e8-5ebb-4b84-a62b-47324949b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff8ec649b90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28b9f45c-1be0-40d8-8a22-e0ce642dd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(W, x, recons_x, h, lam):\n",
    "    \"\"\"Compute the Contractive AutoEncoder Loss\n",
    "    Evalutes the CAE loss, which is composed as the summation of a Mean\n",
    "    Squared Error and the weighted l2-norm of the Jacobian of the hidden\n",
    "    units with respect to the inputs.\n",
    "    Args:\n",
    "        `W` (FloatTensor): (N_hidden x N), where N_hidden and N are the\n",
    "          dimensions of the hidden units and input respectively.\n",
    "        `x` (Variable): the input to the network, with dims (N_batch x N)\n",
    "        recons_x (Variable): the reconstruction of the input, with dims\n",
    "          N_batch x N.\n",
    "        `h` (Variable): the hidden units of the network, with dims\n",
    "          batch_size x N_hidden\n",
    "        `lam` (float): the weight given to the jacobian regulariser term\n",
    "    Returns:\n",
    "        Variable: the (scalar) CAE loss\n",
    "    \"\"\"\n",
    "    mse = mse_loss(recons_x, x)\n",
    "    # Since: W is shape of N_hidden x N. So, we do not need to transpose it as\n",
    "    # opposed to #1\n",
    "    dh = h * (1 - h) # Hadamard product produces size N_batch x N_hidden\n",
    "    # Sum through the input dimension to improve efficiency, as suggested in #1\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "    # unsqueeze to avoid issues with torch.mv\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "    return mse + contractive_loss.mul_(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce8955af-a439-4716-b93d-759a7fcd67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAEtrain(epoch, loader, recon, lam : float = 1e-4):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for idx, (data, _) in enumerate(loader):\n",
    "        data = Variable(data)\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        hidden_representation, recons_x = model(data)\n",
    "        # Get the weights\n",
    "        W = model.state_dict()['fc1.weight']\n",
    "\n",
    "        loss = loss_function(W, data.view(-1, 784), recons_x,\n",
    "                            hidden_representation, lam)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if idx%100==0:\n",
    "            print(loss.data[0]/len(data))\n",
    "        recon = model.save_data(data, epoch, idx, recon)\n",
    "\n",
    "    return recon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0f9bc78-a452-4d7c-885a-0bb6bba518df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads simple mnist dataset\n",
    "def load():\n",
    "    # fetches data\n",
    "    # Using minst dataset provided by sklearn\n",
    "    x, y = sklearn.datasets.fetch_openml('mnist_784', return_X_y=True)\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(int)\n",
    "    y = np.array(y)\n",
    "\n",
    "    with open('MNIST_HD_DF.pickle', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        x_test_D = data['data']\n",
    "        y_test_D = data['label']\n",
    "    \n",
    "    x_test_D = x_test_D.reshape(-1,784)\n",
    "\n",
    "    # split and normalize\n",
    "    x, x_test, y, y_test = sklearn.model_selection.train_test_split(x, y)\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    x_test_D = scaler.transform(x_test_D)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float() \n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float() \n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "    x_test_D = torch.from_numpy(x_test_D).float()\n",
    "    \n",
    "    # preprocessing with CAE\n",
    "    train_loader = DataLoader(CAE.MyDataset(x, y), batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "#     attack_loader = DataLoader(CAE.MyDataset(x_test_D, y_test), batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    recon = torch.zeros(x.shape)\n",
    "    mse_loss = nn.BCELoss(reduction='sum')\n",
    "    for epoch in tqdm(range(4)):\n",
    "        x_tmp = CAEtrain(epoch, train_loader, recon)\n",
    "#     recon = torch.zeros(x_train_D.shape)\n",
    "#     for epoch in range(args.epochs):\n",
    "#         x_train_D = CAEtrain(epoch, attack_loader, recon)\n",
    "\n",
    "#     train_loader = DataLoader(CAE.MyDataset(x_test, y_test), batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "#     attack_loader = DataLoader(CAE.MyDataset(x_test_D, y_test), batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "#     recon = torch.zeros(x_test.shape)\n",
    "#     for epoch in tqdm(range(args.epochs)):\n",
    "#         x_test = CAEtrain(epoch, train_loader, recon)\n",
    "#     recon = torch.zeros(x_test_D.shape)\n",
    "#     for epoch in tqdm(range(args.epochs)):\n",
    "#         x_test_D = CAEtrain(epoch, attack_loader, recon)\n",
    "\n",
    "    return x, x_test, y, y_test, model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1969e371-7dee-4e50-ad7c-0bcbea612e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "args = CAE.Args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 5, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "mse_loss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "model = CAE.CAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "if args.cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9283884b-d0f5-45a3-9b18-e3a144d77529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(543.4429)\n",
      "tensor(44.4497)\n",
      "tensor(41.3416)\n",
      "tensor(40.6125)\n",
      "tensor(41.3480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████                                 | 1/4 [01:59<05:57, 119.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(41.0364)\n",
      "tensor(38.4574)\n",
      "tensor(38.3459)\n",
      "tensor(38.7589)\n",
      "tensor(39.8535)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████                      | 2/4 [04:00<04:00, 120.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39.5987)\n",
      "tensor(37.5289)\n",
      "tensor(37.6671)\n",
      "tensor(38.1836)\n",
      "tensor(39.3383)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████           | 3/4 [05:57<01:58, 118.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(39.0724)\n",
      "tensor(37.1520)\n",
      "tensor(37.3431)\n",
      "tensor(37.8779)\n",
      "tensor(39.0526)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 4/4 [07:52<00:00, 118.03s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Loading...')\n",
    "x, x_test, y, y_test, CAE_model, scaler = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f66f4b64-596b-426c-becf-454e1a3779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_cae = CAE_model.forward(x)\n",
    "_, x_test_cae = CAE_model.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41be9e48-c693-4a68-b164-9ce975762949",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cae = torch.from_numpy(scaler.transform(x_cae.detach().numpy())).float()\n",
    "x_test_cae = torch.from_numpy(scaler.transform(x_test_cae.detach().numpy())).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5afd7023-be24-4cdc-8bf1-6aba9b0aff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "t = 117.119863\n"
     ]
    }
   ],
   "source": [
    "classes = y.unique().size(0)\n",
    "features = x.size(1)\n",
    "model = onlinehd.OnlineHD(classes, features) #OnlineHD initialize\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x_test = x_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "    model = model.to('cuda')\n",
    "    print('Using GPU!')\n",
    "\n",
    "print('Training...')\n",
    "t = time()\n",
    "model = model.fit(x_cae, y, bootstrap=1.0, lr=0.035, epochs=300)\n",
    "t = time() - t\n",
    "print(f'{t = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d28a08d-c4ed-4655-b59e-d076907bf7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "acc = 0.889257\n",
      "acc_test = 0.887143\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "yhat = model(x_cae)\n",
    "yhat_test = model(x_test_cae)\n",
    "\n",
    "acc = (y == yhat).float().mean()\n",
    "acc_test = (y_test == yhat_test).float().mean()\n",
    "\n",
    "print(f'{acc = :6f}')\n",
    "print(f'{acc_test = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dffae85e-c227-4645-8e54-c01cba630d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('hd_adversarial_sample/MNIST_HD_FGSM.pickle', 'rb') as f:\n",
    "    FGSM = pickle.load(f)\n",
    "\n",
    "FGSM_001 = FGSM['data']['0.01']\n",
    "FGSM_003 = FGSM['data']['0.03']\n",
    "FGSM_007 = FGSM['data']['0.07']\n",
    "FGSM_01 = FGSM['data']['0.1']\n",
    "\n",
    "with open('hd_adversarial_sample/MNIST_HD_DF.pickle', 'rb') as f:\n",
    "    DF = pickle.load(f)\n",
    "\n",
    "DF_data = DF['data']\n",
    "\n",
    "with open('hd_adversarial_sample/MNIST_HD_JSMA.pickle', 'rb') as f:\n",
    "    JSMA = pickle.load(f)\n",
    "\n",
    "JSMA_data = JSMA['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17378b82-80e2-469b-886b-65beea6ab395",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, FGSM_001 = CAE_model.forward(FGSM_001)\n",
    "_, FGSM_003 = CAE_model.forward(FGSM_003)\n",
    "_, FGSM_007 = CAE_model.forward(FGSM_007)\n",
    "_, FGSM_01 = CAE_model.forward(FGSM_01)\n",
    "_, DF_data = CAE_model.forward(DF_data)\n",
    "_, JSMA_data = CAE_model.forward(JSMA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a35be550-fc1f-4dea-8d18-f4cab2e2aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FGSM_001 = torch.from_numpy(scaler.transform(FGSM_001.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_003 = torch.from_numpy(scaler.transform(FGSM_003.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_007 = torch.from_numpy(scaler.transform(FGSM_007.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_01 = torch.from_numpy(scaler.transform(FGSM_01.detach().numpy().reshape(-1, 784))).float()\n",
    "DF_data = torch.from_numpy(scaler.transform(DF_data.detach().numpy().reshape(-1, 784))).float()\n",
    "JSMA_data = torch.from_numpy(scaler.transform(JSMA_data.detach().numpy().reshape(-1, 784))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d964d73c-9318-4c36-85d0-33154a7ae166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "FGSM_001_acc = 0.877943\n",
      "FGSM_003_acc = 0.816914\n",
      "FGSM_007_acc = 0.595771\n",
      "FGSM_01_acc = 0.446743\n",
      "DF_acc = 0.872229\n",
      "JSMA_acc = 0.879943\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "\n",
    "FGSM_001_yhat = model(FGSM_001)\n",
    "FGSM_003_yhat = model(FGSM_003)\n",
    "FGSM_007_yhat = model(FGSM_007)\n",
    "FGSM_01_yhat = model(FGSM_01)\n",
    "DF_data_yhat = model(DF_data)\n",
    "JSMA_data_yhat = model(JSMA_data)\n",
    "\n",
    "FGSM_001_acc = (y_test == FGSM_001_yhat).float().mean()\n",
    "FGSM_003_acc = (y_test == FGSM_003_yhat).float().mean()\n",
    "FGSM_007_acc = (y_test == FGSM_007_yhat).float().mean()\n",
    "FGSM_01_acc = (y_test == FGSM_01_yhat).float().mean()\n",
    "DF_acc = (y_test == DF_data_yhat).float().mean()\n",
    "JSMA_acc = (y_test == JSMA_data_yhat).float().mean()\n",
    "\n",
    "print(f'{FGSM_001_acc = :6f}')\n",
    "print(f'{FGSM_003_acc = :6f}')\n",
    "print(f'{FGSM_007_acc = :6f}')\n",
    "print(f'{FGSM_01_acc = :6f}')\n",
    "print(f'{DF_acc = :6f}')\n",
    "print(f'{JSMA_acc = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140636cd-0b9f-440b-9305-707dbd5a2638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCI",
   "language": "python",
   "name": "uci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
