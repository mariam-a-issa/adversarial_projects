{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from torch.autograd import Variable\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from time import time\n",
    "import sklearn.preprocessing\n",
    "import numpy as np\n",
    "import robust_onlinehd\n",
    "from GenAttack import GenAttack"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "scaler = sklearn.preprocessing.Normalizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "torch.manual_seed(54)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbc01aa02f0>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "# loads simple mnist dataset\n",
    "def load():  \n",
    "    (x, y), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()   \n",
    "    y = torch.from_numpy(y).long().squeeze()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long().squeeze()\n",
    "    \n",
    "    if len(x.shape) == 3:\n",
    "        x = x.unsqueeze(3)\n",
    "        x_test = x_test.unsqueeze(3)\n",
    "\n",
    "    return x, x_test, y, y_test\n",
    "\n",
    "\n",
    "print('Loading...')\n",
    "x, x_test, y, y_test = load()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#criterias = [(0, 100, 0), (100, 150, 125), (150, 200, 175), (200, 256, 255)]\n",
    "#criterias = [(0, 50, 0), (50, 100, 75), (100, 125, 124), (125, 150, 149), (150, 175, 174), (175, 200, 199), (200, 225, 224), (225, 256, 255)]\n",
    "#criterias = []\n",
    "#kernel_size = 2\n",
    "kernel_size = 1\n",
    "classes = y.unique().size(0)\n",
    "model = robust_onlinehd.OnlineHD(False, x[0].shape, kernel_size, scaler, classes, dim = 10000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.set_criterias(x, 8)\n",
    "#model.set_criterias([], is_data=False)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    #x = x.cuda()\n",
    "    #y = y.cuda()\n",
    "    #x_test = x_test.cuda()\n",
    "    #y_test = y_test.cuda()\n",
    "    model = model.to(1)\n",
    "    print('Using GPU!')\n",
    "\n",
    "print('Training...')\n",
    "t = time()\n",
    "\n",
    "model = model.fit(x, y, bootstrap=.3, lr=0.095, epochs=300, batch_size=8196)\n",
    "t = time() - t\n",
    "\n",
    "print('Validating...')\n",
    "yhat = model(x).cpu()\n",
    "yhat_test = model(x_test).cpu()\n",
    "acc = (y == yhat).float().mean()\n",
    "acc_test = (y_test == yhat_test).float().mean()\n",
    "print(f'{acc = :6f}')\n",
    "print(f'{acc_test = :6f}')\n",
    "print(f'{t = :6f}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GPU!\n",
      "Training...\n",
      "Validating...\n",
      "acc = 0.999567\n",
      "acc_test = 0.969200\n",
      "t = 30.141647\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "preds = model(x_test).cpu().numpy()\n",
    "#preds = model(x).cpu().numpy() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "targets = torch.randint(0, 10, preds.shape)\n",
    "for i in tqdm(range(len(preds))):\n",
    "    while targets[i] == preds[i]:\n",
    "        targets[i] = torch.randint(0,10, (1,)).item()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 51801.04it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "unif = torch.ones(targets.shape[0])\n",
    "while True:\n",
    "    indices = unif.multinomial(100)\n",
    "    for idx in indices:\n",
    "        if targets[idx] == y_test[idx]:\n",
    "            break\n",
    "    if idx == indices[-1] and targets[idx] != y_test[idx]:\n",
    "        break\n",
    "    else:\n",
    "        indices = unif.multinomial(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "attacker = GenAttack(model, classes, 0.3, 'cuda')\n",
    "N = 8                          # size of population to evolve\n",
    "G = 5000                        # number of generations to evolve through\n",
    "p = torch.FloatTensor([0.9])   # the parameter for Bernoulli distribution used in mutation\n",
    "alpha = torch.FloatTensor([1.0]) # the parameter controlling mutation amount (step-size in the original paper)\n",
    "delta = torch.FloatTensor([.9]) # the parametr controlling mutation amount (norm threshold in the original paper)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "pops = []\n",
    "results = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "t = time()\n",
    "for i in tqdm(indices):\n",
    "    temp = attacker.attack(x_test[i], targets[i], delta, alpha, p, N, G)\n",
    "    pops.append(temp[0].numpy())\n",
    "    results.append(temp[1])\n",
    "t = time() - t\n",
    "\n",
    "print(f'{t = :6f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 1/100 [00:53<1:28:07, 53.41s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All 5000 generations failed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 2/100 [01:47<1:27:24, 53.52s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All 5000 generations failed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  3%|▎         | 3/100 [02:41<1:27:34, 54.17s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All 5000 generations failed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  4%|▍         | 4/100 [03:34<1:25:35, 53.50s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All 5000 generations failed.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  5%|▌         | 5/100 [04:28<1:25:12, 53.82s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All 5000 generations failed.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pops = np.array(pops)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample_preds = preds[indices]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_preds = []\n",
    "for i in range(100):\n",
    "    new_preds.append(model(torch.tensor(pops[i])).cpu().numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "success = 0\n",
    "success_idx = []\n",
    "for i in range(100):\n",
    "    if targets[indices[i]].item() in new_preds[i]:\n",
    "        success_idx.append((indices[i].item(), (i, np.where(new_preds[i] == targets[indices[i]].item())[0][0])))\n",
    "        success += 1\n",
    "print(success)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cache = {\n",
    "    'indices' : indices,\n",
    "    'sample_preds' : sample_preds,\n",
    "    'pops' : np.array(pops),\n",
    "    'hyper_parameter' : [N, G, p, alpha, delta],\n",
    "    'success_idx' : success_idx,\n",
    "    'model' : model, \n",
    "    'scaler' : model.scaler,\n",
    "    'targets' : targets,\n",
    "    'results' : results\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.save(cache, 'robust_onlinehd_mnist.pt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model(torch.tensor(pops[13]))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([8, 8, 8, 8, 8, 8, 8, 8], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = {\n",
    "    0 : '0',\n",
    "    1 : '1',\n",
    "    2 : '2',\n",
    "    3 : '3',\n",
    "    4 : '4',\n",
    "    5 : '5',\n",
    "    6 : '6',\n",
    "    7 : '7',\n",
    "    8 : '8',\n",
    "    9 : '9'\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "origin_idx, (new_idx, new_idx_idx) = success_idx[torch.randint(0, len(success_idx), (1,)).item()]\n",
    "\n",
    "f, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(x_test[origin_idx], cmap=plt.gray())\n",
    "_ = axes[0].set_title('Properly classified : %s' % labels[sample_preds[new_idx].item()])\n",
    "axes[1].imshow(pops[new_idx][new_idx_idx].astype(np.int32))\n",
    "_ = axes[1].set_title('Misclassified : %s' % labels[new_preds[new_idx][new_idx_idx]])"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "random_ expects 'from' to be less than 'to', but got from=0 >= to=0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-37df94a4035d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0morigin_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_idx_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccess_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuccess_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morigin_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Properly classified : %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: random_ expects 'from' to be less than 'to', but got from=0 >= to=0"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('py38': conda)"
  },
  "interpreter": {
   "hash": "3db542ac60b6226dd50a79a39a56822b2dbbe89167b91e3ffb64b8d7c630bc20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}