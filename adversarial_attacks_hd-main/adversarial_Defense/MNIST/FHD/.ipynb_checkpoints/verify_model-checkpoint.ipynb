{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from torchvision.datasets import EMNIST\n",
    "from time import time\n",
    "import numpy as np\n",
    "import robust_onlinehd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = 'mnist'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# loads simple mnist dataset\n",
    "def load():\n",
    "    if dataset == 'mnist':\n",
    "        (x, y), (x_test, y_test) = mnist.load_data()\n",
    "    elif dataset == 'fashion_mnist':\n",
    "        (x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    else:\n",
    "        temp = EMNIST('./data/EMNIST', split = 'letters', train = True, download = True)\n",
    "        x = temp.data.unsqueeze(3).numpy().transpose((0,2,1,3))\n",
    "        y = temp.targets.numpy() - 1\n",
    "\n",
    "        temp = EMNIST('./data/EMNIST', split = 'letters', train = False, download = True)\n",
    "        x_test = temp.data.unsqueeze(3).numpy().transpose((0,2,1,3))\n",
    "        y_test = temp.targets.numpy() - 1 \n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()   \n",
    "    y = torch.from_numpy(y).long().squeeze()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long().squeeze()\n",
    "    \n",
    "    if len(x.shape) == 3:\n",
    "        x = x.unsqueeze(3)\n",
    "        x_test = x_test.unsqueeze(3)\n",
    "\n",
    "    return x, x_test, y, y_test\n",
    "\n",
    "\n",
    "print('Loading...')\n",
    "x, x_test, y, y_test = load()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "seeds = ['seed27', 'seed33', 'seed54', 'seed71', 'seed88']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hp = 'hp1'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "robust_cache = []\n",
    "for seed in seeds:\n",
    "    robust_cache.append(torch.load('%s/%s/full_result/robust_onlinehd_%s.pt' % (hp, seed, dataset)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "origin_cache = []\n",
    "for seed in seeds:\n",
    "    origin_cache.append(torch.load('%s/%s/nothing/robust_onlinehd_%s.pt' % (hp, seed, dataset)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pops = np.concatenate([origin_cache[i]['pops'] for i in range(len(origin_cache))])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imgs = [[] for i in range(len(origin_cache))]\n",
    "misclassified = [[] for i in range(len(origin_cache))]\n",
    "correct = [[] for i in range(len(origin_cache))]\n",
    "for i in range(len(origin_cache)):\n",
    "    pops = origin_cache[i]['pops']\n",
    "    success_idx = origin_cache[i]['success_idx']\n",
    "    indices = origin_cache[i]['indices']\n",
    "    targets = origin_cache[i]['targets']\n",
    "    for s in success_idx:\n",
    "        imgs[i].append(pops[s[1][0]][s[1][1]])\n",
    "        misclassified[i].append(targets[s[0]].item())\n",
    "        correct[i].append(y_test[s[0]].item())\n",
    "imgs = [torch.Tensor(imgs[i]).float() for i in range(len(origin_cache))]\n",
    "correct = [torch.Tensor(correct[i]).float() for i in range(len(origin_cache))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "models = []\n",
    "for r in robust_cache:\n",
    "    models.append(r['model'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "success = 0\n",
    "for m in range(len(models)):\n",
    "    success += (correct[m] == models[m](imgs[m]).cpu()).sum().item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "total = np.array([len(c) for c in correct]).sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(success / total)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if dataset == 'emnist':\n",
    "    labels = {\n",
    "        0 : 'a',\n",
    "        1 : 'b',\n",
    "        2 : 'c',\n",
    "        3 : 'd',\n",
    "        4 : 'e',\n",
    "        5 : 'f',\n",
    "        6 : 'g',\n",
    "        7 : 'h',\n",
    "        8 : 'i',\n",
    "        9 : 'j',\n",
    "        10 : 'k',\n",
    "        11 : 'l',\n",
    "        12 : 'm',\n",
    "        13 : 'n',\n",
    "        14 : 'o',\n",
    "        15 : 'p',\n",
    "        16 : 'q',\n",
    "        17 : 'r',\n",
    "        18 : 's',\n",
    "        19 : 't',\n",
    "        20 : 'u',\n",
    "        21 : 'v',\n",
    "        22 : 'w',\n",
    "        23 : 'x',\n",
    "        24 : 'y',\n",
    "        25 : 'z'\n",
    "    }\n",
    "elif dataset == 'mnist':\n",
    "    labels = {\n",
    "        0 : '0',\n",
    "        1 : '1',\n",
    "        2 : '2',\n",
    "        3 : '3',\n",
    "        4 : '4',\n",
    "        5 : '5',\n",
    "        6 : '6',\n",
    "        7 : '7',\n",
    "        8 : '8',\n",
    "        9 : '9'\n",
    "    }\n",
    "else:\n",
    "    labels = {\n",
    "        0 : 'T-shirt/top',\n",
    "        1 : 'Trouser',\n",
    "        2 : 'Pullover',\n",
    "        3 : 'Dress',\n",
    "        4 : 'Coat',\n",
    "        5 : 'Sandal',\n",
    "        6 : 'Shirt',\n",
    "        7 : 'Sneaker',\n",
    "        8 : 'Bag',\n",
    "        9 : 'Ankle boot'\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "idx1 = torch.randint(0, len(imgs), (1,))\n",
    "idx2 = torch.randint(0, len(imgs[idx1]), (1,))\n",
    "print(idx1.item(), idx2.item())\n",
    "f, axes = plt.subplots(1, 2)\n",
    "axes[0].imshow(imgs[idx1][idx2].squeeze(), cmap=plt.gray())\n",
    "_ = axes[0].set_title('Robust model : %s' % labels[models[0](imgs[idx1][idx2]).item()])\n",
    "axes[1].imshow(imgs[idx1][idx2].squeeze())\n",
    "_ = axes[1].set_title('Origin model : %s' % labels[misclassified[idx1][idx2]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "eminst = 125, 183 \n",
    "\n",
    "fashion mnist = 209, 253, 224\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "imgs = []\n",
    "misclassified = []\n",
    "correct = []\n",
    "for i in range(len(origin_cache)):\n",
    "    pops = origin_cache[i]['pops']\n",
    "    success_idx = origin_cache[i]['success_idx']\n",
    "    indices = origin_cache[i]['indices']\n",
    "    targets = origin_cache[i]['targets']\n",
    "    for s in success_idx:\n",
    "        imgs.append(pops[s[1][0]][s[1][1]])\n",
    "        misclassified.append(targets[s[0]].item())\n",
    "        correct.append(y_test[s[0]].item())\n",
    "imgs = torch.Tensor(imgs).float()\n",
    "correct = torch.Tensor(correct).float()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "success = 0\n",
    "for m in range(len(models)):\n",
    "    success += (correct == models[m](imgs).cpu()).sum().item()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "success = success / len(models)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "success / total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.imshow(imgs[206])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.imshow(models[0].quantizing(models[0].local_maximum(imgs[206].unsqueeze(0))).squeeze())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.imshow(models[0].quantizing(imgs[206].unsqueeze(0)).squeeze())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f, axes = plt.subplots(1, 4)\n",
    "f.set_figheight(15)\n",
    "f.set_figwidth(15)\n",
    "axes[0].imshow(imgs[150], cmap=plt.gray())\n",
    "_ = axes[0].set_title('original image')\n",
    "axes[1].imshow(models[0].local_maximum(imgs[150].unsqueeze(0)).squeeze())\n",
    "_ = axes[1].set_title('local maximum only')\n",
    "axes[2].imshow(models[0].quantizing(imgs[150].unsqueeze(0)).squeeze())\n",
    "_ = axes[2].set_title('quantization only')\n",
    "axes[3].imshow(models[0].quantizing(models[0].local_maximum(imgs[150].unsqueeze(0))).squeeze())\n",
    "_ = axes[3].set_title('maxpooling + quantization')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('py38': conda)"
  },
  "interpreter": {
   "hash": "3db542ac60b6226dd50a79a39a56822b2dbbe89167b91e3ffb64b8d7c630bc20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}