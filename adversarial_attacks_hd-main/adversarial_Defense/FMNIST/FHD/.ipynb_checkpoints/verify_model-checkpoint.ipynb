{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from torchvision.datasets import EMNIST\n",
    "from time import time\n",
    "import numpy as np\n",
    "import robust_onlinehd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    }
   ],
   "source": [
    "# loads simple mnist dataset\n",
    "def load():\n",
    "    if dataset == 'mnist':\n",
    "        (x, y), (x_test, y_test) = mnist.load_data()\n",
    "    elif dataset == 'fashion_mnist':\n",
    "        (x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    else:\n",
    "        temp = EMNIST('./data/EMNIST', split = 'letters', train = True, download = True)\n",
    "        x = temp.data.unsqueeze(3).numpy().transpose((0,2,1,3))\n",
    "        y = temp.targets.numpy() - 1\n",
    "\n",
    "        temp = EMNIST('./data/EMNIST', split = 'letters', train = False, download = True)\n",
    "        x_test = temp.data.unsqueeze(3).numpy().transpose((0,2,1,3))\n",
    "        y_test = temp.targets.numpy() - 1 \n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float()   \n",
    "    y = torch.from_numpy(y).long().squeeze()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long().squeeze()\n",
    "    \n",
    "    if len(x.shape) == 3:\n",
    "        x = x.unsqueeze(3)\n",
    "        x_test = x_test.unsqueeze(3)\n",
    "\n",
    "    return x, x_test, y, y_test\n",
    "\n",
    "\n",
    "print('Loading...')\n",
    "x, x_test, y, y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = ['seed27', 'seed33', 'seed54', 'seed71', 'seed88']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = 'hp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_cache = []\n",
    "for seed in seeds:\n",
    "    robust_cache.append(torch.load('robust_onlinehd_mnist.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_cache = []\n",
    "for seed in seeds:\n",
    "    origin_cache.append(torch.load('robust_onlinehd_mnist.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops = np.concatenate([origin_cache[i]['pops'] for i in range(len(origin_cache))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [[] for i in range(len(origin_cache))]\n",
    "misclassified = [[] for i in range(len(origin_cache))]\n",
    "correct = [[] for i in range(len(origin_cache))]\n",
    "for i in range(len(origin_cache)):\n",
    "    pops = origin_cache[i]['pops']\n",
    "    success_idx = origin_cache[i]['success_idx']\n",
    "    indices = origin_cache[i]['indices']\n",
    "    targets = origin_cache[i]['targets']\n",
    "    for s in success_idx:\n",
    "        imgs[i].append(pops[s[1][0]][s[1][1]])\n",
    "        misclassified[i].append(targets[s[0]].item())\n",
    "        correct[i].append(y_test[s[0]].item())\n",
    "imgs = [torch.Tensor(imgs[i]).float() for i in range(len(origin_cache))]\n",
    "correct = [torch.Tensor(correct[i]).float() for i in range(len(origin_cache))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for r in robust_cache:\n",
    "    models.append(r['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongseongheon/opt/anaconda3/envs/UCI/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "for m in range(len(models)):\n",
    "    success += (correct[m] == models[m](imgs[m]).cpu()).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.array([len(c) for c in correct]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(success / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('hd_adversarial_sample/MNIST_HD_FGSM.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hd_adversarial_sample/MNIST_HD_DF.pickle', 'rb') as f:\n",
    "    data2 = pickle.load(f)\n",
    "    \n",
    "with open('hd_adversarial_sample/MNIST_HD_JSMA.pickle', 'rb') as f:\n",
    "    data3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "FGSM001 = data['data']['0.01']\n",
    "FGSM003 = data['data']['0.03']\n",
    "FGSM007 = data['data']['0.07']\n",
    "FGSM01 = data['data']['0.1']\n",
    "DF = data2['data']\n",
    "JSMA = data3['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17500, 784])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_001 = torch.zeros(17500, 28, 28)\n",
    "for i in range(17500):\n",
    "    min_ = FGSM001[i].min()\n",
    "    max_ = FGSM001[i].max()\n",
    "\n",
    "    fgsm_001[i] = ((FGSM001[i] - min_) / (max_ - min_))*255\n",
    "    \n",
    "fgsm_003 = torch.zeros(17500, 28, 28)\n",
    "for i in range(17500):\n",
    "    min_ = FGSM003[i].min()\n",
    "    max_ = FGSM003[i].max()\n",
    "\n",
    "    fgsm_003[i] = ((FGSM003[i] - min_) / (max_ - min_))*255\n",
    "    \n",
    "fgsm_007 = torch.zeros(17500, 28, 28)\n",
    "for i in range(17500):\n",
    "    min_ = FGSM007[i].min()\n",
    "    max_ = FGSM007[i].max()\n",
    "\n",
    "    fgsm_007[i] = ((FGSM007[i] - min_) / (max_ - min_))*255\n",
    "    \n",
    "fgsm_01 = torch.zeros(17500, 28, 28)\n",
    "for i in range(17500):\n",
    "    min_ = FGSM01[i].min()\n",
    "    max_ = FGSM01[i].max()\n",
    "\n",
    "    fgsm_01[i] = ((FGSM01[i] - min_) / (max_ - min_))*255\n",
    "    \n",
    "df = torch.zeros(17500, 28, 28)\n",
    "for i in range(17500):\n",
    "    min_ = DF[i].min()\n",
    "    max_ = DF[i].max()\n",
    "\n",
    "    df[i] = (((DF[i] - min_) / (max_ - min_))*255).reshape(28, 28)\n",
    "    \n",
    "jsma = torch.zeros(17500, 28, 28)\n",
    "for i in range(17500):\n",
    "    min_ = JSMA[i].min()\n",
    "    max_ = JSMA[i].max()\n",
    "\n",
    "    jsma[i] = (((JSMA[i] - min_) / (max_ - min_))*255).reshape(28, 28)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_fgsm_001 = models[1](fgsm_001.reshape(-1, 28, 28, 1))\n",
    "y_pred_fgsm_003 = models[1](fgsm_003.reshape(-1, 28, 28, 1))\n",
    "y_pred_fgsm_007 = models[1](fgsm_007.reshape(-1, 28, 28, 1))\n",
    "y_pred_fgsm_01 = models[1](fgsm_01.reshape(-1, 28, 28, 1))\n",
    "y_pred_df = models[1](df.reshape(-1, 28, 28, 1))\n",
    "y_pred_jsma = models[1](jsma.reshape(-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(data['label'].long() == y_pred_fgsm_001) / len(y_pred_fgsm_001))\n",
    "print(sum(data['label'].long() == y_pred_fgsm_003) / len(y_pred_fgsm_003))\n",
    "print(sum(data['label'].long() == y_pred_fgsm_007) / len(y_pred_fgsm_007))\n",
    "print(sum(data['label'].long() == y_pred_fgsm_01) / len(y_pred_fgsm_01))\n",
    "print(sum(data['label'].long() == y_pred_df) / len(y_pred_fgsm_01))\n",
    "print(sum(data['label'].long() == y_pred_jsma) / len(y_pred_fgsm_01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3db542ac60b6226dd50a79a39a56822b2dbbe89167b91e3ffb64b8d7c630bc20"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
