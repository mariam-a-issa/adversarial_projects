{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33e7d3e-8998-44a0-9a75-bcce7e51cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import onlinehd\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.datasets import FashionMNIST as FMNIST\n",
    "from torchvision.datasets import EMNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from onlinehd import CAE\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "# import pdb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a891d7e8-5ebb-4b84-a62b-47324949b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fae78443b10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28b9f45c-1be0-40d8-8a22-e0ce642dd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(W, x, recons_x, h, lam):\n",
    "    \"\"\"Compute the Contractive AutoEncoder Loss\n",
    "    Evalutes the CAE loss, which is composed as the summation of a Mean\n",
    "    Squared Error and the weighted l2-norm of the Jacobian of the hidden\n",
    "    units with respect to the inputs.\n",
    "    Args:\n",
    "        `W` (FloatTensor): (N_hidden x N), where N_hidden and N are the\n",
    "          dimensions of the hidden units and input respectively.\n",
    "        `x` (Variable): the input to the network, with dims (N_batch x N)\n",
    "        recons_x (Variable): the reconstruction of the input, with dims\n",
    "          N_batch x N.\n",
    "        `h` (Variable): the hidden units of the network, with dims\n",
    "          batch_size x N_hidden\n",
    "        `lam` (float): the weight given to the jacobian regulariser term\n",
    "    Returns:\n",
    "        Variable: the (scalar) CAE loss\n",
    "    \"\"\"\n",
    "    mse = mse_loss(recons_x, x)\n",
    "    # Since: W is shape of N_hidden x N. So, we do not need to transpose it as\n",
    "    # opposed to #1\n",
    "    dh = h * (1 - h) # Hadamard product produces size N_batch x N_hidden\n",
    "    # Sum through the input dimension to improve efficiency, as suggested in #1\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "    # unsqueeze to avoid issues with torch.mv\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "    return mse + contractive_loss.mul_(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8955af-a439-4716-b93d-759a7fcd67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAEtrain(epoch, loader, recon, lam : float = 1e-4):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for idx, (data, _) in enumerate(loader):\n",
    "        data = Variable(data)\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        hidden_representation, recons_x = model(data)\n",
    "        # Get the weights\n",
    "        W = model.state_dict()['fc1.weight']\n",
    "\n",
    "        loss = loss_function(W, data.view(-1, 784), recons_x,\n",
    "                            hidden_representation, lam)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if idx%100==0:\n",
    "            print(loss.data[0]/len(data))\n",
    "        recon = model.save_data(data, epoch, idx, recon)\n",
    "\n",
    "    return recon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20b884ec-6d37-471d-b717-ebc236855cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emnist():\n",
    "    download_root = 'data/emnist_dataset'\n",
    "    \n",
    "    temp = EMNIST(download_root, split = 'letters', train=True, download=True)\n",
    "    x = temp.data.unsqueeze(3).numpy().transpose((0,2,1,3))\n",
    "    y = temp.targets.numpy() - 1\n",
    "    temp = EMNIST(download_root, split='letters', train=False, download=True)\n",
    "    x_test = temp.data.unsqueeze(3).numpy().transpose((0,2,1,3))\n",
    "    y_test = temp.targets.numpy() - 1\n",
    "    \n",
    "    x = torch.from_numpy(x).float()\n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "    \n",
    "    x_test = x_test.float()\n",
    "    y_test = y_test.long().squeeze()\n",
    "\n",
    "    if len(x.shape) != 3:\n",
    "        x = x.squeeze(3)\n",
    "        x_test = x_test.squeeze(3)\n",
    "    \n",
    "    return x, x_test, y, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f9bc78-a452-4d7c-885a-0bb6bba518df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads simple mnist dataset\n",
    "def load():\n",
    "    # fetches data\n",
    "    # Using minst dataset provided by sklearn\n",
    "    x, x_test, y, y_test = load_emnist()\n",
    "    \n",
    "    x = x.reshape(-1, 784)\n",
    "    x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "    # split and normalize\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float() \n",
    "    x_test = torch.from_numpy(x_test).float() \n",
    "    \n",
    "    # preprocessing with CAE\n",
    "    train_loader = DataLoader(CAE.MyDataset(x, y), batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    recon = torch.zeros(x.shape)\n",
    "    mse_loss = nn.BCELoss(reduction='sum')\n",
    "    for epoch in tqdm(range(5)):\n",
    "        x_tmp = CAEtrain(epoch, train_loader, recon)\n",
    "\n",
    "    return x, x_test, y, y_test, model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1969e371-7dee-4e50-ad7c-0bcbea612e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "args = CAE.Args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 5, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "mse_loss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "model = CAE.CAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "if args.cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9283884b-d0f5-45a3-9b18-e3a144d77529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(543.3779)\n",
      "tensor(57.1498)\n",
      "tensor(52.0549)\n",
      "tensor(51.1553)\n",
      "tensor(50.7175)\n",
      "tensor(48.3563)\n",
      "tensor(47.9995)\n",
      "tensor(47.8592)\n",
      "tensor(48.7654)\n",
      "tensor(48.0000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 1/5 [04:31<18:04, 271.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48.2422)\n",
      "tensor(48.1074)\n",
      "tensor(47.6414)\n",
      "tensor(48.1736)\n",
      "tensor(48.5051)\n",
      "tensor(46.7687)\n",
      "tensor(46.7034)\n",
      "tensor(46.6507)\n",
      "tensor(47.8350)\n",
      "tensor(47.1743)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 2/5 [08:58<13:27, 269.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47.4431)\n",
      "tensor(47.3633)\n",
      "tensor(47.0136)\n",
      "tensor(47.5724)\n",
      "tensor(47.9504)\n",
      "tensor(46.2549)\n",
      "tensor(46.2545)\n",
      "tensor(46.1899)\n",
      "tensor(47.4394)\n",
      "tensor(46.8116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████▍                 | 3/5 [13:26<08:56, 268.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(47.1021)\n",
      "tensor(47.0023)\n",
      "tensor(46.7269)\n",
      "tensor(47.2796)\n",
      "tensor(47.6780)\n",
      "tensor(45.9948)\n",
      "tensor(46.0252)\n",
      "tensor(45.9495)\n",
      "tensor(47.2210)\n",
      "tensor(46.6081)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████▏        | 4/5 [17:52<04:27, 267.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46.9131)\n",
      "tensor(46.8040)\n",
      "tensor(46.5680)\n",
      "tensor(47.1161)\n",
      "tensor(47.5232)\n",
      "tensor(45.8470)\n",
      "tensor(45.8872)\n",
      "tensor(45.8245)\n",
      "tensor(47.0992)\n",
      "tensor(46.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [22:18<00:00, 267.75s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Loading...')\n",
    "x, x_test, y, y_test, CAE_model, scaler = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f66f4b64-596b-426c-becf-454e1a3779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_cae = CAE_model.forward(x)\n",
    "_, x_test_cae = CAE_model.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d20c8a2-515b-4b27-a1e6-1ca2187cbab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_cae[-1].detach().numpy().reshape(28, 28), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41be9e48-c693-4a68-b164-9ce975762949",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cae = torch.from_numpy(scaler.transform(x_cae.detach().numpy())).float()\n",
    "x_test_cae = torch.from_numpy(scaler.transform(x_test_cae.detach().numpy())).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5afd7023-be24-4cdc-8bf1-6aba9b0aff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "t = 574.512593\n"
     ]
    }
   ],
   "source": [
    "classes = y.unique().size(0)\n",
    "features = x.size(1)\n",
    "model = onlinehd.OnlineHD(classes, features) #OnlineHD initialize\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x_test = x_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "    model = model.to('cuda')\n",
    "    print('Using GPU!')\n",
    "\n",
    "print('Training...')\n",
    "t = time()\n",
    "model = model.fit(x_cae, y, bootstrap=1.0, lr=0.035, epochs=300)\n",
    "t = time() - t\n",
    "print(f'{t = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c40a2a00-0780-44f1-987e-38330ced219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "acc = 0.688373\n",
      "acc_test = 0.680962\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "yhat = model(x_cae)\n",
    "yhat_test = model(x_test_cae)\n",
    "\n",
    "acc = (y == yhat).float().mean()\n",
    "acc_test = (y_test == yhat_test).float().mean()\n",
    "\n",
    "print(f'{acc = :6f}')\n",
    "print(f'{acc_test = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dffae85e-c227-4645-8e54-c01cba630d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('hd_adversarial_sample/EMNIST_HD_FGSM.pickle', 'rb') as f:\n",
    "    FGSM = pickle.load(f)\n",
    "\n",
    "FGSM_001 = FGSM['data']['0.01']\n",
    "FGSM_003 = FGSM['data']['0.03']\n",
    "FGSM_007 = FGSM['data']['0.07']\n",
    "FGSM_01 = FGSM['data']['0.1']\n",
    "\n",
    "with open('hd_adversarial_sample/EMNIST_HD_DF.pickle', 'rb') as f:\n",
    "    DF = pickle.load(f)\n",
    "\n",
    "DF_data = DF['data']\n",
    "\n",
    "with open('hd_adversarial_sample/EMNIST_HD_JSMA.pickle', 'rb') as f:\n",
    "    JSMA = pickle.load(f)\n",
    "\n",
    "JSMA_data = JSMA['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17378b82-80e2-469b-886b-65beea6ab395",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, FGSM_001 = CAE_model.forward(FGSM_001)\n",
    "_, FGSM_003 = CAE_model.forward(FGSM_003)\n",
    "_, FGSM_007 = CAE_model.forward(FGSM_007)\n",
    "_, FGSM_01 = CAE_model.forward(FGSM_01)\n",
    "_, DF_data = CAE_model.forward(DF_data)\n",
    "_, JSMA_data = CAE_model.forward(JSMA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a35be550-fc1f-4dea-8d18-f4cab2e2aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FGSM_001 = torch.from_numpy(scaler.transform(FGSM_001.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_003 = torch.from_numpy(scaler.transform(FGSM_003.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_007 = torch.from_numpy(scaler.transform(FGSM_007.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_01 = torch.from_numpy(scaler.transform(FGSM_01.detach().numpy().reshape(-1, 784))).float()\n",
    "DF_data = torch.from_numpy(scaler.transform(DF_data.detach().numpy().reshape(-1, 784))).float()\n",
    "JSMA_data = torch.from_numpy(scaler.transform(JSMA_data.detach().numpy().reshape(-1, 784))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d964d73c-9318-4c36-85d0-33154a7ae166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "FGSM_001_acc = 0.667548\n",
      "FGSM_003_acc = 0.585144\n",
      "FGSM_007_acc = 0.303077\n",
      "FGSM_01_acc = 0.175769\n",
      "DF_acc = 0.677740\n",
      "JSMA_acc = 0.663750\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "\n",
    "FGSM_001_yhat = model(FGSM_001)\n",
    "FGSM_003_yhat = model(FGSM_003)\n",
    "FGSM_007_yhat = model(FGSM_007)\n",
    "FGSM_01_yhat = model(FGSM_01)\n",
    "DF_data_yhat = model(DF_data)\n",
    "JSMA_data_yhat = model(JSMA_data)\n",
    "\n",
    "FGSM_001_acc = (y_test == FGSM_001_yhat).float().mean()\n",
    "FGSM_003_acc = (y_test == FGSM_003_yhat).float().mean()\n",
    "FGSM_007_acc = (y_test == FGSM_007_yhat).float().mean()\n",
    "FGSM_01_acc = (y_test == FGSM_01_yhat).float().mean()\n",
    "DF_acc = (y_test == DF_data_yhat).float().mean()\n",
    "JSMA_acc = (y_test == JSMA_data_yhat).float().mean()\n",
    "\n",
    "print(f'{FGSM_001_acc = :6f}')\n",
    "print(f'{FGSM_003_acc = :6f}')\n",
    "print(f'{FGSM_007_acc = :6f}')\n",
    "print(f'{FGSM_01_acc = :6f}')\n",
    "print(f'{DF_acc = :6f}')\n",
    "print(f'{JSMA_acc = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140636cd-0b9f-440b-9305-707dbd5a2638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCI",
   "language": "python",
   "name": "uci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
