{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d33e7d3e-8998-44a0-9a75-bcce7e51cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import torch\n",
    "import sklearn.datasets\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import onlinehd\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from onlinehd import CAE\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "# import pdb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a891d7e8-5ebb-4b84-a62b-47324949b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff19b245b10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b9f45c-1be0-40d8-8a22-e0ce642dd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(W, x, recons_x, h, lam):\n",
    "    \"\"\"Compute the Contractive AutoEncoder Loss\n",
    "    Evalutes the CAE loss, which is composed as the summation of a Mean\n",
    "    Squared Error and the weighted l2-norm of the Jacobian of the hidden\n",
    "    units with respect to the inputs.\n",
    "    Args:\n",
    "        `W` (FloatTensor): (N_hidden x N), where N_hidden and N are the\n",
    "          dimensions of the hidden units and input respectively.\n",
    "        `x` (Variable): the input to the network, with dims (N_batch x N)\n",
    "        recons_x (Variable): the reconstruction of the input, with dims\n",
    "          N_batch x N.\n",
    "        `h` (Variable): the hidden units of the network, with dims\n",
    "          batch_size x N_hidden\n",
    "        `lam` (float): the weight given to the jacobian regulariser term\n",
    "    Returns:\n",
    "        Variable: the (scalar) CAE loss\n",
    "    \"\"\"\n",
    "    mse = mse_loss(recons_x, x)\n",
    "    # Since: W is shape of N_hidden x N. So, we do not need to transpose it as\n",
    "    # opposed to #1\n",
    "    dh = h * (1 - h) # Hadamard product produces size N_batch x N_hidden\n",
    "    # Sum through the input dimension to improve efficiency, as suggested in #1\n",
    "    w_sum = torch.sum(Variable(W)**2, dim=1)\n",
    "    # unsqueeze to avoid issues with torch.mv\n",
    "    w_sum = w_sum.unsqueeze(1) # shape N_hidden x 1\n",
    "    contractive_loss = torch.sum(torch.mm(dh**2, w_sum), 0)\n",
    "    return mse + contractive_loss.mul_(lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce8955af-a439-4716-b93d-759a7fcd67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAEtrain(epoch, loader, recon, lam : float = 1e-4):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for idx, (data, _) in enumerate(loader):\n",
    "        data = Variable(data)\n",
    "        if args.cuda:\n",
    "            data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        hidden_representation, recons_x = model(data)\n",
    "        # Get the weights\n",
    "        W = model.state_dict()['fc1.weight']\n",
    "\n",
    "        loss = loss_function(W, data.view(-1, 784), recons_x,\n",
    "                            hidden_representation, lam)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        if idx%100==0:\n",
    "            print(loss.data[0]/len(data))\n",
    "        recon = model.save_data(data, epoch, idx, recon)\n",
    "\n",
    "    return recon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6368d641-6ab4-499f-a173-a70e3a6e8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fe951f1-c8a5-495f-8c52-c8edf73984c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0f9bc78-a452-4d7c-885a-0bb6bba518df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "\n",
    "# loads simple mnist dataset\n",
    "def load():\n",
    "    # fetches data\n",
    "    # Using minst dataset provided by sklearn\n",
    "    (x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    x = x.reshape(-1, 784)\n",
    "    x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "    # split and normalize\n",
    "    scaler = sklearn.preprocessing.Normalizer().fit(x)\n",
    "    x = scaler.transform(x)\n",
    "    x_test = scaler.transform(x_test)\n",
    "\n",
    "    # changes data to pytorch's tensors\n",
    "    x = torch.from_numpy(x).float() \n",
    "    y = torch.from_numpy(y).long()\n",
    "    x_test = torch.from_numpy(x_test).float() \n",
    "    y_test = torch.from_numpy(y_test).long()\n",
    "    \n",
    "    # preprocessing with CAE\n",
    "    train_loader = DataLoader(CAE.MyDataset(x, y), batch_size=args.batch_size, shuffle=False, **kwargs)\n",
    "    recon = torch.zeros(x.shape)\n",
    "    mse_loss = nn.BCELoss(reduction='sum')\n",
    "    for epoch in tqdm(range(5)):\n",
    "        x_tmp = CAEtrain(epoch, train_loader, recon)\n",
    "\n",
    "    return x, x_test, y, y_test, model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1969e371-7dee-4e50-ad7c-0bcbea612e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "args = CAE.Args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "kwargs = {'num_workers': 5, 'pin_memory': True} if args.cuda else {}\n",
    "\n",
    "mse_loss = nn.BCELoss(reduction='sum')\n",
    "\n",
    "model = CAE.CAE()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "if args.cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9283884b-d0f5-45a3-9b18-e3a144d77529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(543.2977)\n",
      "tensor(75.6761)\n",
      "tensor(72.2294)\n",
      "tensor(71.5990)\n",
      "tensor(73.7374)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▊                                   | 1/5 [02:10<08:41, 130.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(70.6829)\n",
      "tensor(72.4270)\n",
      "tensor(70.6026)\n",
      "tensor(70.5036)\n",
      "tensor(72.9628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▌                          | 2/5 [04:20<06:30, 130.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.9784)\n",
      "tensor(71.8898)\n",
      "tensor(70.1238)\n",
      "tensor(70.0933)\n",
      "tensor(72.6122)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████████▍                 | 3/5 [06:26<04:16, 128.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.6448)\n",
      "tensor(71.6257)\n",
      "tensor(69.8578)\n",
      "tensor(69.8270)\n",
      "tensor(72.3937)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████▏        | 4/5 [08:32<02:07, 127.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.4398)\n",
      "tensor(71.4463)\n",
      "tensor(69.6842)\n",
      "tensor(69.6381)\n",
      "tensor(72.2333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [10:39<00:00, 127.92s/it]\n"
     ]
    }
   ],
   "source": [
    "print('Loading...')\n",
    "x, x_test, y, y_test, CAE_model, scaler = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66f4b64-596b-426c-becf-454e1a3779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x_cae = CAE_model.forward(x)\n",
    "_, x_test_cae = CAE_model.forward(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d20c8a2-515b-4b27-a1e6-1ca2187cbab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test_cae[-1].detach().numpy().reshape(28, 28), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41be9e48-c693-4a68-b164-9ce975762949",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cae = torch.from_numpy(scaler.transform(x_cae.detach().numpy())).float()\n",
    "x_test_cae = torch.from_numpy(scaler.transform(x_test_cae.detach().numpy())).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5afd7023-be24-4cdc-8bf1-6aba9b0aff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "t = 138.736526\n"
     ]
    }
   ],
   "source": [
    "classes = y.unique().size(0)\n",
    "features = x.size(1)\n",
    "model = onlinehd.OnlineHD(classes, features) #OnlineHD initialize\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x_test = x_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "    model = model.to('cuda')\n",
    "    print('Using GPU!')\n",
    "\n",
    "print('Training...')\n",
    "t = time()\n",
    "model = model.fit(x_cae, y, bootstrap=1.0, lr=0.035, epochs=300)\n",
    "t = time() - t\n",
    "print(f'{t = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15066528-5860-42ba-b1e0-44ac50e3bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(x, y, bootstrap=1.0, lr=0.035, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a2a00-0780-44f1-987e-38330ced219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Validating...')\n",
    "yhat = model(x_cae)\n",
    "yhat_test = model(x_test_cae)\n",
    "\n",
    "acc = (y == yhat).float().mean()\n",
    "acc_test = (y_test == yhat_test).float().mean()\n",
    "\n",
    "print(f'{acc = :6f}')\n",
    "print(f'{acc_test = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d28a08d-c4ed-4655-b59e-d076907bf7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "acc = 0.787383\n",
      "acc_test = 0.778600\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "yhat = model(x_cae)\n",
    "yhat_test = model(x_test_cae)\n",
    "\n",
    "acc = (y == yhat).float().mean()\n",
    "acc_test = (y_test == yhat_test).float().mean()\n",
    "\n",
    "print(f'{acc = :6f}')\n",
    "print(f'{acc_test = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dffae85e-c227-4645-8e54-c01cba630d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('hd_adversarial_sample/FMNIST_HD_FGSM.pickle', 'rb') as f:\n",
    "    FGSM = pickle.load(f)\n",
    "\n",
    "FGSM_001 = FGSM['data']['0.01']\n",
    "FGSM_003 = FGSM['data']['0.03']\n",
    "FGSM_007 = FGSM['data']['0.07']\n",
    "FGSM_01 = FGSM['data']['0.1']\n",
    "\n",
    "with open('hd_adversarial_sample/FMNIST_HD_DF.pickle', 'rb') as f:\n",
    "    DF = pickle.load(f)\n",
    "\n",
    "DF_data = DF['data']\n",
    "DF_data = torch.from_numpy(DF_data)\n",
    "\n",
    "with open('hd_adversarial_sample/FMNIST_HD_JSMA.pickle', 'rb') as f:\n",
    "    JSMA = pickle.load(f)\n",
    "\n",
    "JSMA_data = JSMA['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17378b82-80e2-469b-886b-65beea6ab395",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, FGSM_001 = CAE_model.forward(FGSM_001)\n",
    "_, FGSM_003 = CAE_model.forward(FGSM_003)\n",
    "_, FGSM_007 = CAE_model.forward(FGSM_007)\n",
    "_, FGSM_01 = CAE_model.forward(FGSM_01)\n",
    "_, DF_data = CAE_model.forward(DF_data)\n",
    "_, JSMA_data = CAE_model.forward(JSMA_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a35be550-fc1f-4dea-8d18-f4cab2e2aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FGSM_001 = torch.from_numpy(scaler.transform(FGSM_001.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_003 = torch.from_numpy(scaler.transform(FGSM_003.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_007 = torch.from_numpy(scaler.transform(FGSM_007.detach().numpy().reshape(-1, 784))).float()\n",
    "FGSM_01 = torch.from_numpy(scaler.transform(FGSM_01.detach().numpy().reshape(-1, 784))).float()\n",
    "DF_data = torch.from_numpy(scaler.transform(DF_data.detach().numpy().reshape(-1, 784))).float()\n",
    "JSMA_data = torch.from_numpy(scaler.transform(JSMA_data.detach().numpy().reshape(-1, 784))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d964d73c-9318-4c36-85d0-33154a7ae166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "FGSM_001_acc = 0.738800\n",
      "FGSM_003_acc = 0.555900\n",
      "FGSM_007_acc = 0.226400\n",
      "FGSM_01_acc = 0.157800\n",
      "DF_acc = 0.722400\n",
      "JSMA_acc = 0.770300\n"
     ]
    }
   ],
   "source": [
    "print('Validating...')\n",
    "\n",
    "FGSM_001_yhat = model(FGSM_001)\n",
    "FGSM_003_yhat = model(FGSM_003)\n",
    "FGSM_007_yhat = model(FGSM_007)\n",
    "FGSM_01_yhat = model(FGSM_01)\n",
    "DF_data_yhat = model(DF_data)\n",
    "JSMA_data_yhat = model(JSMA_data)\n",
    "\n",
    "FGSM_001_acc = (y_test == FGSM_001_yhat).float().mean()\n",
    "FGSM_003_acc = (y_test == FGSM_003_yhat).float().mean()\n",
    "FGSM_007_acc = (y_test == FGSM_007_yhat).float().mean()\n",
    "FGSM_01_acc = (y_test == FGSM_01_yhat).float().mean()\n",
    "DF_acc = (y_test == DF_data_yhat).float().mean()\n",
    "JSMA_acc = (y_test == JSMA_data_yhat).float().mean()\n",
    "\n",
    "print(f'{FGSM_001_acc = :6f}')\n",
    "print(f'{FGSM_003_acc = :6f}')\n",
    "print(f'{FGSM_007_acc = :6f}')\n",
    "print(f'{FGSM_01_acc = :6f}')\n",
    "print(f'{DF_acc = :6f}')\n",
    "print(f'{JSMA_acc = :6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140636cd-0b9f-440b-9305-707dbd5a2638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UCI",
   "language": "python",
   "name": "uci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
